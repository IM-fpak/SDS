{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from autocorrect import spell \n",
    "import matplotlib\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stopwords.words('english')\n",
    "import warnings\n",
    "from nltk import word_tokenize, corpus\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "sns.set() # use seaborn plotting style\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57885 entries, 0 to 19243\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Sentiment   57885 non-null  object\n",
      " 1   score       57885 non-null  int64 \n",
      " 2   comms_num   57885 non-null  int64 \n",
      " 3   timestamp   57885 non-null  object\n",
      " 4   clean_text  57885 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20\" ><caption>Sentiment overview</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Sentiment</th>        <th class=\"col_heading level0 col1\" >Entries</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row0_col0\" class=\"data row0 col0\" >Negative</td>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row0_col1\" class=\"data row0 col1\" >15690</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row1_col0\" class=\"data row1 col0\" >Neutral</td>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row1_col1\" class=\"data row1 col1\" >21017</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row2_col0\" class=\"data row2 col0\" >Positive</td>\n",
       "                        <td id=\"T_b6356eb9_8896_11eb_8b23_3ca0678e0b20row2_col1\" class=\"data row2 col1\" >21178</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a48cb62850>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data and merge them  \n",
    "title=pd.read_csv(\"title_sentiment.csv\")\n",
    "body=pd.read_csv(\"body_sentiment.csv\")\n",
    "\n",
    "## make clean text\n",
    "title.rename({'clean_title': 'clean_text'}, axis=1, inplace=True)\n",
    "body.rename({'clean_body': 'clean_text'}, axis=1, inplace=True)\n",
    "\n",
    "#make new df with all text and sentiments \n",
    "df=pd.concat([title, body], axis=0)\n",
    "# change column to string \n",
    "df['clean_text']=df['clean_text'].apply(str)\n",
    "\n",
    "#look at ddta\n",
    "print(df.info()) \n",
    "sents_count=pd.DataFrame(df.groupby(\"Sentiment\")[\"Sentiment\"].count()).rename(columns={\"Sentiment\":\"Entries\"}).reset_index().style.set_caption(\"Sentiment overview\")\n",
    "sents_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentiment', 'clean_text']\n"
     ]
    }
   ],
   "source": [
    "# dropping the columns we dont need\n",
    "df.drop(columns=['score', 'comms_num', 'timestamp'], inplace=True)\n",
    "df\n",
    "print (list(df))\n",
    "df['clean_text']=df['clean_text'].apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(row):\n",
    "    posts = row['clean_text']\n",
    "    tokens = nltk.word_tokenize(posts)\n",
    "    # taken only words (not punctuation)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "df['words'] = df.apply(make_tokens, axis=1)\n",
    "\n",
    "#dropping the rows where the string is empty \n",
    "df=df[df['words'].map(lambda d: len(d)) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lemmatize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def Lemmatizer(row):\n",
    "    my_list = row['words']\n",
    "    lemma_list = [lemmatizer.lemmatize(word) for word in my_list]\n",
    "    return (lemma_list)\n",
    "\n",
    "df['lemmatized_words'] = df.apply(Lemmatizer, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "### removing stopwords \n",
    "\n",
    "stops = set(stopwords.words(\"english\"))                  \n",
    "\n",
    "def remove_stops(row):\n",
    "    my_list = row['lemmatized_words']\n",
    "    meaningful_words = [w for w in my_list if not w in stops]\n",
    "    return (meaningful_words)\n",
    "\n",
    "df['lemma_meaningful'] = df.apply(remove_stops, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make back into string \n",
    "\n",
    "def make_string(row):\n",
    "    my_list = row['lemma_meaningful']\n",
    "    joined_words = ( \" \".join(my_list))\n",
    "    return joined_words\n",
    "\n",
    "df['processed'] = df.apply(make_string, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop irrelavant columns \n",
    "df.drop(columns=['clean_text', 'words', 'lemmatized_words'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create csv \n",
    "\n",
    "# create csv file \n",
    "df.to_csv('processed_data.csv',index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
