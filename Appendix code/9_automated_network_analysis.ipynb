{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import ChainMap\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data: Network data and node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "os.chdir(r'C:\\Users\\maril\\Documents\\20-21 KU\\block 4\\DM\\twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edgelist\n",
    "de_temp_edgelist = pd.read_csv('final_data_prepare1\\de_edgelist_rt.csv', dtype = {'source':str,'target':str})\n",
    "da_temp_edgelist = pd.read_csv('final_data_prepare1\\da_edgelist_rt.csv', dtype = {'source':str,'target':str})\n",
    "pl_temp_edgelist = pd.read_csv('final_data_prepare1\\pl_edgelist_rt.csv', dtype = {'source':str,'target':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the node labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe\n",
    "de = pd.read_csv(r'network_analysis\\automated_network\\de_labelled_users.csv')\n",
    "da = pd.read_csv(r'network_analysis\\automated_network\\da_labelled_users.csv')\n",
    "pl = pd.read_csv(r'network_analysis\\automated_network\\pl_labelled_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframes to only include anti-vax, pro-vax and neutral users\n",
    "de = de[de['labels']!='trash']\n",
    "da = da[da['labels']!='trash']\n",
    "pl = pl[pl['labels']!='trash']\n",
    "\n",
    "# reset index\n",
    "de.reset_index(inplace=True, drop=True)\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "pl.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all edges to or from a trash user\n",
    "\n",
    "def remove_trash_edges(df, edgelist):\n",
    "\n",
    "    # create set of all relevant users\n",
    "    user_set = set(user for user in df['user'])\n",
    "    \n",
    "    # lists to store the final edges in\n",
    "    source_list = [] \n",
    "    target_list = []\n",
    "\n",
    "    # iterate through length of dataset\n",
    "    for i in range(len(edgelist)):\n",
    "        \n",
    "        # retrieve the target and source user name\n",
    "        source = edgelist['source'][i]\n",
    "        target = edgelist['target'][i]\n",
    "        \n",
    "        if source in user_set:\n",
    "            if target in user_set:\n",
    "                source_list.append(source)\n",
    "                target_list.append(target)\n",
    "                \n",
    "    # update the edgelist\n",
    "    edgelist_final = pd.DataFrame(list(zip(source_list, target_list)), columns=['source','target'])\n",
    "        \n",
    "    return edgelist_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_edgelist = remove_trash_edges(de, de_temp_edgelist)\n",
    "da_edgelist = remove_trash_edges(da, da_temp_edgelist)\n",
    "pl_edgelist = remove_trash_edges(pl, pl_temp_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a user and label column\n",
    "def label_column(df):\n",
    "    \n",
    "    # create a dictionary of users and their labels\n",
    "    label_dict = dict(zip(df['user'], df['labels']))\n",
    "\n",
    "    # create the final node dict (dict of dicts) to be passed\n",
    "    node_dict = {}\n",
    "\n",
    "    for i in label_dict:\n",
    "        node_dict[i] = {'type':label_dict[i]}\n",
    "    \n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to datasets\n",
    "de_node_dict = label_column(de)\n",
    "da_node_dict = label_column(da)\n",
    "pl_node_dict = label_column(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree centrality (entire network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the degree centrality of the network (here: undirected degree centrality)\n",
    "\n",
    "def degree_centrality(edgelist):\n",
    "    \n",
    "    # create directed graph from all nodes and edges that we read in as an edgelist\n",
    "    G = nx.from_pandas_edgelist(edgelist, source='source', target='target')\n",
    "\n",
    "    # degree centrality for all nodes\n",
    "    cent = nx.degree_centrality(G)\n",
    "\n",
    "    # turn centrality into a dataframe\n",
    "    cent_df = pd.DataFrame(cent.items(),columns=['user', 'degree']).sort_values(by='degree', ascending=False)\n",
    "\n",
    "    # calculate the mean degree centrality in this network\n",
    "    degree_cent = cent_df['degree'].mean()\n",
    "    \n",
    "    return degree_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_deg = degree_centrality(de_edgelist)\n",
    "da_deg = degree_centrality(da_edgelist)\n",
    "pl_deg = degree_centrality(pl_edgelist)\n",
    "\n",
    "# print the results\n",
    "print(f'German data: Degree centrality of {de_deg}')\n",
    "print(f'Danish data: Degree centrality of {da_deg}')\n",
    "print(f'Polish data: Degree centrality of {pl_deg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted, directed network\n",
    "First we calculate the edge weights, then we create the directed network based on the edgelist.\n",
    "  \n",
    "An edge is drawn if source retweets target, i.e.:\n",
    "* nodes with high indegree = nodes receiving a lot of retweets\n",
    "* nodes with high outdegree = nodes retweeting others a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the weights\n",
    "\n",
    "def graph(edgelist, node_dict):\n",
    "    \n",
    "    # calculate the edge weights\n",
    "    weighted_edgelist = pd.DataFrame(edgelist.groupby(edgelist.columns.tolist(),as_index=False).size())\n",
    "    weighted_edgelist = weighted_edgelist.rename(columns={'size':'weight'})\n",
    "    weighted_edgelist = weighted_edgelist.sort_values('weight', ascending=False)\n",
    "    \n",
    "    # create directed graph from all nodes and edges that we read in as an edgelist\n",
    "    DiG = nx.from_pandas_edgelist(weighted_edgelist, \n",
    "                                  source='source', \n",
    "                                  target='target', \n",
    "                                  edge_attr=['weight'], \n",
    "                                  create_using= nx.DiGraph)\n",
    "    \n",
    "    # set the node attributes\n",
    "    nx.set_node_attributes(DiG, node_dict)\n",
    "\n",
    "    return DiG, weighted_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "DiG_de, de_weighted_edgelist = graph(de_edgelist, de_node_dict)\n",
    "DiG_da, da_weighted_edgelist = graph(da_edgelist, da_node_dict)\n",
    "DiG_pl, pl_weighted_edgelist = graph(pl_edgelist, pl_node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the standardized indegree and outdegree measures for all nodes and save as dictionaries\n",
    "\n",
    "def in_out(DiG):\n",
    "\n",
    "    # in- and outdegree centrality\n",
    "    idc_dict = nx.in_degree_centrality(DiG)\n",
    "    odc_dict = nx.out_degree_centrality(DiG)\n",
    "\n",
    "    # turn the dictionaries into a dict of dicts in order to pass it as a node attribute\n",
    "    deg_dict = dict(ChainMap(idc_dict, odc_dict))\n",
    "\n",
    "    # create the final node dict (dict of dicts) to be passed\n",
    "    node_degree_dict = {}\n",
    "\n",
    "    for i in deg_dict:\n",
    "        node_degree_dict[i] = {'idc':deg_dict[i], 'odc':deg_dict[i]}\n",
    "        \n",
    "    # set the indegree and outdegree centrality as node attributes\n",
    "    nx.set_node_attributes(DiG, node_degree_dict)\n",
    "    \n",
    "    # retrieve the accounts with the highest indegree and outdegree: turn the 'idc' and 'odc' dict into a dataframe\n",
    "    idc = pd.DataFrame(idc_dict.items(),columns=['user', 'indegree']).sort_values(by='indegree', ascending=False)\n",
    "    odc = pd.DataFrame(idc_dict.items(),columns=['user', 'outdegree']).sort_values(by='outdegree', ascending=False)\n",
    "    \n",
    "    return DiG, idc, odc, node_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_DiG, de_idc, de_odc, de_node_degree_dict = in_out(DiG_de)\n",
    "da_DiG, da_idc, da_odc, da_node_degree_dict = in_out(DiG_da)\n",
    "pl_DiG, pl_idc, pl_odc, pl_node_degree_dict = in_out(DiG_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the German df's\n",
    "display(\"Users with highest indegree\", de_idc.head(5), \"Users with highest outdegree\", de_odc.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display Danish df's\n",
    "display(\"Users with highest indegree\", da_idc.head(5), \"Users with highest outdegree\", da_odc.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Users with highest indegree\", pl_idc.head(5), \"Users with highest outdegree\", pl_odc.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection\n",
    "\n",
    "The general goal of community detection is to find cohesive subgroups (= communities) within the network. For this to work, we need to treat the network (which is originally both weighted and directed) as a weighted and undirected network.\n",
    "  \n",
    "### Modularity\n",
    "Here we calculate communities based on modularity (Louvian community detection algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create graph and perform community detection\n",
    "\n",
    "def louvain_comm(weighted_edgelist, node_degree_dict, node_dict):\n",
    "\n",
    "    # create an undirected, weighted graph\n",
    "    UG = nx.from_pandas_edgelist(weighted_edgelist, \n",
    "                                 source='source', \n",
    "                                 target='target', \n",
    "                                 edge_attr=['weight'])\n",
    "    \n",
    "    # add labels\n",
    "    nx.set_node_attributes(UG, node_dict)\n",
    "    \n",
    "    # add indegree and outdegree centrality\n",
    "    nx.set_node_attributes(UG, node_degree_dict)\n",
    "    \n",
    "    # Louvain community detection on weighted graph\n",
    "    partition = community_louvain.best_partition(UG, weight='weight')\n",
    "    \n",
    "    # add community as node attribute\n",
    "    for c in partition:\n",
    "        UG.nodes[c]['community'] = partition[c]\n",
    "    \n",
    "    return UG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_UG = louvain_comm(de_weighted_edgelist, de_node_degree_dict, de_node_dict)\n",
    "da_UG = louvain_comm(da_weighted_edgelist, da_node_degree_dict, da_node_dict)\n",
    "pl_UG = louvain_comm(pl_weighted_edgelist, pl_node_degree_dict, pl_node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number nodes and edges in each graph\n",
    "print(f'German network: {len(de_UG.nodes)} nodes and {len(de_UG.edges)} edges')\n",
    "print(f'Danish network: {len(da_UG.nodes)} nodes and {len(da_UG.edges)} edges')\n",
    "print(f'Polish network: {len(pl_UG.nodes)} nodes and {len(pl_UG.edges)} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to Gephi\n",
    "nx.write_gexf(de_UG, r'network_analysis\\automated_network\\rt_network_louvain_de2.gexf')\n",
    "nx.write_gexf(da_UG, r'network_analysis\\automated_network\\rt_network_louvain_da2.gexf')\n",
    "nx.write_gexf(pl_UG, r'network_analysis\\automated_network\\rt_network_louvain_pl2.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-core decomposition\n",
    "\n",
    "The k-core decomposition technique is often used to distinguish between the core and the periphery of a network. In order to do so, the algorithm divides the network into layers (also called k-shells). Each k-shell contains nodes which are equally well or better connected than all other nodes in that k-shell. In other words, the nodes in the high k-shells make up the core of the network because they are not only well connected, but they are well connected to other central (= well connected) nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose network\n",
    "\n",
    "def decompose(UG):\n",
    "    \n",
    "    # remove self-loops (otherwise the networkx can't decompose the network)\n",
    "    UG.remove_edges_from(nx.selfloop_edges(UG))\n",
    "\n",
    "    # Computing the coresness of each country\n",
    "    G_coreness = nx.core_number(UG)\n",
    "\n",
    "    # Returns a dictionary of the maximum k-core of each node\n",
    "    G_coreness\n",
    "    \n",
    "    # add core number as node attribute\n",
    "    for c in G_coreness:\n",
    "        UG.nodes[c]['kshell'] = G_coreness[c]\n",
    "        \n",
    "    # turn the results into a pandas df\n",
    "    core_df = pd.DataFrame(G_coreness.items(),columns=['user', 'shell']).sort_values(by='shell', ascending=False)\n",
    "    \n",
    "    return UG, core_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_UG, de_core_df = decompose(de_UG)\n",
    "da_UG, da_core_df = decompose(da_UG)\n",
    "pl_UG, pl_core_df = decompose(pl_UG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the highest k-shell?\n",
    "print('German data: Highest k-shell is', max(de_core_df['shell']))\n",
    "print('Danish data: Highest k-shell is', max(da_core_df['shell']))\n",
    "print('Polish data: Highest k-shell is', max(pl_core_df['shell']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the users in the highest k-shell\n",
    "\n",
    "def max_shell_users(core_df):\n",
    "    # empty set to store the user handles in\n",
    "    core_users = set()\n",
    "\n",
    "    # number of the highest k-shell\n",
    "    max_shell = max(core_df['shell'])\n",
    "    \n",
    "    # get the users in the highest shells (i.e. the top 20% of shells)    \n",
    "    for i in range(int(max_shell * 0.5)):\n",
    "    \n",
    "        # iterate through all users in the highest shell and add the names to the 'core_users' set\n",
    "        for user in core_df.loc[core_df['shell'] == max_shell-i, 'user']:\n",
    "            core_users.add(user)\n",
    "\n",
    "    return core_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_core_users = max_shell_users(de_core_df)\n",
    "da_core_users = max_shell_users(da_core_df)\n",
    "pl_core_users = max_shell_users(pl_core_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the anti-vaxx actors in the highest k-shell\n",
    "\n",
    "def anti_vax_shell(df, core_users):\n",
    "    \n",
    "    # create set of anti-vaxx accounts\n",
    "    anti_vaxx_users = set()\n",
    "\n",
    "    # check which users in the highest k-shell are anti-vax actors\n",
    "    for user in core_users:\n",
    "\n",
    "        if df[df['user'] == user]['labels'].values[0] == 'anti-vaxx':\n",
    "            anti_vaxx_users.add(user)\n",
    "\n",
    "    return anti_vaxx_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_anti_vaxx = anti_vax_shell(de, de_core_users)\n",
    "da_anti_vaxx = anti_vax_shell(da, da_core_users)\n",
    "pl_anti_vaxx = anti_vax_shell(pl, pl_core_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization as plots: Percentage of anti-vax actors across k-shells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_vax_proportion(df, UG):\n",
    "\n",
    "    # create set of anti-vaxx accounts\n",
    "    anti_vaxx_users = set()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "   \n",
    "        if df['labels'][i] == 'anti-vaxx':\n",
    "            anti_vaxx_users.add(df['user'][i])  \n",
    "            \n",
    "    # check how many anti-vaxxers there are in each community\n",
    "    # retrieve the 'kshell' node attribute as a dictionary\n",
    "    shell = nx.get_node_attributes(UG, name='kshell')\n",
    "\n",
    "    # turn the 'comm' dict into a dataframe\n",
    "    shell_df = pd.DataFrame(shell.items(),columns=['user', 'kshell']).sort_values(by='kshell', ascending=True)\n",
    "\n",
    "    # add a 'anti_vaxx' column that is set to 0\n",
    "    shell_df['anti-vaxx'] = 0\n",
    "\n",
    "    # loop through the rows in the comm_df dataframe\n",
    "    for i in range(len(shell_df['user'])):\n",
    "\n",
    "        # if the user is in bot_set, update the value in the 'bot' column to 1\n",
    "        if shell_df['user'][i] in anti_vaxx_users:\n",
    "            shell_df.iloc[i,2] = 1\n",
    "\n",
    "    # group the shell_df dataframe by 'anti-vaxx' to see how many anti-vaccine users there are in each shell\n",
    "    shell_group_df = pd.DataFrame(shell_df.groupby(['kshell','anti-vaxx']).user.count().unstack(level = 1))\n",
    "    \n",
    "    # rename the columns\n",
    "    shell_group_df.columns = ['num_vaxxer', 'num_anti_vaxxer']\n",
    "    \n",
    "    # calculate percentages\n",
    "    # add a total column\n",
    "    shell_group_df['num_total'] = shell_group_df['num_vaxxer'] + shell_group_df['num_anti_vaxxer']\n",
    "    \n",
    "    # calculate percentages\n",
    "    shell_group_df['pct_anti_vaxxer_nodes'] = shell_group_df['num_anti_vaxxer']/shell_group_df['num_total']\n",
    "    \n",
    "    # replace NaN values by 0\n",
    "    shell_group_df.loc[shell_group_df['pct_anti_vaxxer_nodes'].isna(), 'pct_anti_vaxxer_nodes'] = 0\n",
    "\n",
    "    # display the dataframe\n",
    "    shell_group_df.head(len(shell_group_df))\n",
    "    \n",
    "    return shell_group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "de_shell_group_df = anti_vax_proportion(de, de_UG)\n",
    "da_shell_group_df = anti_vax_proportion(da, da_UG)\n",
    "pl_shell_group_df = anti_vax_proportion(pl, pl_UG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plots\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(ncols=3, figsize=(20,4))\n",
    "\n",
    "# Danish data\n",
    "ax1.plot('pct_anti_vaxxer_nodes', '.', color='#1E337F', data=da_shell_group_df)\n",
    "\n",
    "# y axis\n",
    "ylim1 = ax1.get_ylim()\n",
    "ax1.set_ylim(0, ylim1[1])\n",
    "\n",
    "# axis labels\n",
    "ax1.set_xlabel('K-shell')\n",
    "ax1.set_ylabel('Percentage of anti-vaccine users')\n",
    "\n",
    "# title\n",
    "ax1.set_title('Danish data: Percentage of anti-vaccine users per k-shell')\n",
    "\n",
    "# German data\n",
    "ax2.plot('pct_anti_vaxxer_nodes', '.', color='#1E337F', data=de_shell_group_df)\n",
    "\n",
    "# y axis\n",
    "ylim2 = ax2.get_ylim()\n",
    "ax2.set_ylim(0,ylim1[1])\n",
    "\n",
    "# axis labels\n",
    "ax2.set_xlabel('K-shell')\n",
    "ax2.set_ylabel('Percentage of anti-vaccine users')\n",
    "\n",
    "# title\n",
    "ax2.set_title('German data: Percentage of anti-vaccine users per k-shell')\n",
    "\n",
    "\n",
    "# Polish data\n",
    "ax3.plot('pct_anti_vaxxer_nodes', '.', color='#1E337F', data=pl_shell_group_df)\n",
    "\n",
    "# y axis\n",
    "ylim3 = ax3.get_ylim()\n",
    "ax3.set_ylim(0,ylim1[1])\n",
    "\n",
    "# axis labels\n",
    "ax3.set_xlabel('K-shell')\n",
    "ax3.set_ylabel('Percentage of anti-vaccine users')\n",
    "\n",
    "# title\n",
    "_ = ax3.set_title('Polish data: Percentage of anti-vaccine users per k-shell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot\n",
    "fig.savefig(r'network_analysis\\automated_network\\antivax_scatter.png',dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
