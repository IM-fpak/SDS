{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``langdetect`` to filter non-Danish/German/Polish tweets\n",
    "\n",
    "This notebook exemplifies how we used the ``langdetect`` package. We ran this on all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "from langdetect import DetectorFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir(r'C:\\Users\\maril\\Documents\\20-21 KU\\block 4\\DM\\twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(r'sanity_check\\de_sanity_check.csv', dtype = {'id': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ``langdetect`` package that detects languages based on the text it is given. It doesn't work perfectly on tweets because they are so short and people use more informal language, so we really need to go through and double check the results manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting and checking all tweets that seem to be foreign language\n",
    "\n",
    "# set the seed\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# we will store all words that are classified as non-German in the 'nogerman' list\n",
    "nogerman = []\n",
    "\n",
    "# sometimes there are no meaningful words to predict a language from and this raises an LangDetectException error\n",
    "# we want to catch all of these exceptions and check them manually\n",
    "exceptions = []\n",
    "\n",
    "# iterate through the text in the dataframe\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        # if the detected language is not German, add the tweet id to the 'nogerman' list\n",
    "        \n",
    "        # change to 'da' for Danish and 'pl' for Polish\n",
    "        if detect(df.iloc[i]['text']) != 'de':\n",
    "            nogerman.append(df.iloc[i]['id'])\n",
    "    \n",
    "    # if an exception is raised, add the tweet id to the 'exceptions' list\n",
    "    except LangDetectException:\n",
    "        exceptions.append(df.iloc[i]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the 'exceptions' list\n",
    "for ids in exceptions:\n",
    "    t = df.loc[df['id']==ids, 'text']\n",
    "    print(t.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the 'nogerman' list\n",
    "for ids in nogerman:\n",
    "    t = df.loc[df['id']==ids, 'text']\n",
    "    print(t.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
